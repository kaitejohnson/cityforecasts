// Stan model code generated by package mvgam
functions {
  /* Function to compute the matrix square root */

  /* see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)*/
  matrix sqrtm(matrix A) {
    int m = rows(A);
    vector[m] root_root_evals = sqrt(sqrt(eigenvalues_sym(A)));
    matrix[m, m] evecs = eigenvectors_sym(A);
    matrix[m, m] eprod = diag_post_multiply(evecs, root_root_evals);
    return tcrossprod(eprod);
  }
  /* Function to transform P_real to P */

  /* see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)*/
  matrix P_realtoP(matrix P_real) {
    int m = rows(P_real);
    matrix[m, m] B = tcrossprod(P_real);
    for (i in 1 : m) {
      B[i, i] += 1.0;
    }
    return mdivide_left_spd(sqrtm(B), P_real);
  }
  /* Function to perform the reverse mapping*/

  /* see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)*/
  array[,] matrix rev_mapping(array[] matrix P, matrix Sigma) {
    int p = size(P);
    int m = rows(Sigma);
    array[p, p] matrix[m, m] phi_for;
    array[p, p] matrix[m, m] phi_rev;
    array[p + 1] matrix[m, m] Sigma_for;
    array[p + 1] matrix[m, m] Sigma_rev;
    matrix[m, m] S_for;
    matrix[m, m] S_rev;
    array[p + 1] matrix[m, m] S_for_list;
    array[p + 1] matrix[m, m] Gamma_trans;
    array[2, p] matrix[m, m] phiGamma;

    // Step 1:
    Sigma_for[p + 1] = Sigma;
    S_for_list[p + 1] = sqrtm(Sigma);
    for (s in 1 : p) {
      // In this block of code S_rev is B^{-1} and S_for is a working matrix
      S_for = -tcrossprod(P[p - s + 1]);
      for (i in 1 : m) {
        S_for[i, i] += 1.0;
      }
      S_rev = sqrtm(S_for);
      S_for_list[p - s + 1] = mdivide_right_spd(mdivide_left_spd(S_rev,
                                                                 sqrtm(
                                                                 quad_form_sym(
                                                                 Sigma_for[
                                                                 p - s + 2],
                                                                 S_rev))),
                                                S_rev);
      Sigma_for[p - s + 1] = tcrossprod(S_for_list[p - s + 1]);
    }

    // Step 2:
    Sigma_rev[1] = Sigma_for[1];
    Gamma_trans[1] = Sigma_for[1];
    for (s in 0 : (p - 1)) {
      S_for = S_for_list[s + 1];
      S_rev = sqrtm(Sigma_rev[s + 1]);
      phi_for[s + 1, s + 1] = mdivide_right_spd(S_for * P[s + 1], S_rev);
      phi_rev[s + 1, s + 1] = mdivide_right_spd(S_rev * P[s + 1]', S_for);
      Gamma_trans[s + 2] = phi_for[s + 1, s + 1] * Sigma_rev[s + 1];
      if (s >= 1) {
        for (k in 1 : s) {
          phi_for[s + 1, k] = phi_for[s, k]
                              - phi_for[s + 1, s + 1] * phi_rev[s, s - k + 1];
          phi_rev[s + 1, k] = phi_rev[s, k]
                              - phi_rev[s + 1, s + 1] * phi_for[s, s - k + 1];
        }
        for (k in 1 : s) {
          Gamma_trans[s + 2] = Gamma_trans[s + 2]
                               + phi_for[s, k] * Gamma_trans[s + 2 - k];
        }
      }
      Sigma_rev[s + 2] = Sigma_rev[s + 1]
                         - quad_form_sym(Sigma_for[s + 1],
                                         phi_rev[s + 1, s + 1]');
    }
    for (i in 1 : p) {
      phiGamma[1, i] = phi_for[p, i];
    }
    for (i in 1 : p) {
      phiGamma[2, i] = Gamma_trans[i]';
    }
    return phiGamma;
  }
  vector rep_each(vector x, int K) {
    int N = rows(x);
    vector[N * K] y;
    int pos = 1;
    for (n in 1 : N) {
      for (k in 1 : K) {
        y[pos] = x[n];
        pos += 1;
      }
    }
    return y;
  }
}
data {
  int<lower=0> total_obs; // total number of observations
  int<lower=0> n; // number of timepoints per series
  int<lower=0> n_sp_trend; // number of trend smoothing parameters
  int<lower=0> n_lv; // number of dynamic factors
  int<lower=0> n_series; // number of series
  matrix[n_series, n_lv] Z; // matrix mapping series to latent states
  int<lower=0> num_basis; // total number of basis coefficients
  int<lower=0> num_basis_trend; // number of trend basis coefficients
  vector[num_basis_trend] zero_trend; // prior locations for trend basis coefficients
  matrix[total_obs, num_basis] X; // mgcv GAM design matrix
  matrix[n * n_lv, num_basis_trend] X_trend; // trend model design matrix
  array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?)
  array[n, n_lv] int ytimes_trend;
  int<lower=0> n_nonmissing; // number of nonmissing observations
  matrix[10, 10] S_trend1; // mgcv smooth penalty matrix S_trend1
  matrix[10, 10] S_trend2; // mgcv smooth penalty matrix S_trend2
  matrix[10, 10] S_trend3; // mgcv smooth penalty matrix S_trend3
  matrix[10, 10] S_trend4; // mgcv smooth penalty matrix S_trend4
  matrix[10, 10] S_trend5; // mgcv smooth penalty matrix S_trend5
  matrix[10, 10] S_trend6; // mgcv smooth penalty matrix S_trend6
  vector<lower=0, upper=1>[n_nonmissing] flat_ys; // flattened nonmissing observations
  matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations
  array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations
  array[5] int trend_rand_idxs; // trend random effect indices
}
transformed data {
  // exchangeable partial autocorrelation hyperparameters

  // see Heaps 2022 for details (https://doi.org/10.1080/10618600.2022.2079648)
  vector[2] es;
  vector<lower=0>[2] fs;
  vector<lower=0>[2] gs;
  vector<lower=0>[2] hs;
  es[1] = 0;
  es[2] = 0;
  fs[1] = sqrt(0.455);
  fs[2] = sqrt(0.455);
  gs[1] = 1.365;
  gs[2] = 1.365;
  hs[1] = 0.071175;
  hs[2] = 0.071175;
}
parameters {
  // raw basis coefficients
  vector[num_basis] b_raw;
  vector[num_basis_trend] b_raw_trend;

  // trend random effects
  vector<lower=0>[1] sigma_raw_trend;
  vector[1] mu_raw_trend;

  // Beta precision parameters
  vector<lower=0>[n_series] phi;

  // latent state variance parameters
  cholesky_factor_corr[n_lv] L_Omega;
  vector<lower=0.2, upper=1>[n_lv] sigma;

  // unconstrained VAR1 partial autocorrelations
  matrix[n_lv, n_lv] P_real;

  // partial autocorrelation hyperparameters
  vector[2] Pmu;
  vector<lower=0>[2] Pomega;

  // latent states
  array[n] vector[n_lv] LV;

  // smoothing parameters
  vector<lower=0>[n_sp_trend] lambda_trend;
}
transformed parameters {
  // latent state VAR1 autoregressive terms
  matrix[n_lv, n_lv] A;

  // LKJ form of covariance matrix
  matrix[n_lv, n_lv] L_Sigma;

  // computed error covariance matrix
  cov_matrix[n_lv] Sigma;

  // initial trend covariance
  cov_matrix[n_lv] Gamma;

  // basis coefficients
  vector[num_basis] b;
  vector[num_basis_trend] b_trend;

  // latent states and loading matrix
  vector[n * n_lv] trend_mus;
  matrix[n, n_series] trend;
  matrix[n_series, n_lv] lv_coefs;

  // process model basis coefficients
  b_trend[1 : 60] = b_raw_trend[1 : 60];
  b_trend[61 : 65] = mu_raw_trend[1]
                     + b_raw_trend[61 : 65] * sigma_raw_trend[1];

  // latent process linear predictors
  trend_mus = X_trend * b_trend;

  // derived latent states
  lv_coefs = Z;
  for (i in 1 : n) {
    for (s in 1 : n_series) {
      trend[i, s] = dot_product(lv_coefs[s,  : ], LV[i]);
    }
  }
  L_Sigma = diag_pre_multiply(sigma, L_Omega);
  Sigma = multiply_lower_tri_self_transpose(L_Sigma);

  // stationary VAR reparameterisation
  {
    array[1] matrix[n_lv, n_lv] P;
    array[2, 1] matrix[n_lv, n_lv] phiGamma;
    P[1] = P_realtoP(P_real);
    phiGamma = rev_mapping(P, Sigma);
    A = phiGamma[1, 1];
    Gamma = phiGamma[2, 1];
  }

  // observation model basis coefficients
  b[1 : num_basis] = b_raw[1 : num_basis];

  // (Intercept) fixed at zero
  b[1] = 0;
}
model {
  // latent state mean parameters
  array[n] vector[n_lv] mu;

  // prior for (Intercept)...
  b_raw[1] ~ student_t(3, 0, 2.5);

  // priors for latent state variance parameters
  sigma ~ beta(3, 3);

  // LKJ error correlation prior
  L_Omega ~ lkj_corr_cholesky(2);

  // partial autocorrelation hyperpriors
  Pmu ~ normal(es, fs);
  Pomega ~ gamma(gs, hs);

  // unconstrained partial autocorrelations
  diagonal(P_real) ~ normal(Pmu[1], 1 / sqrt(Pomega[1]));
  for (i in 1 : n_lv) {
    for (j in 1 : n_lv) {
      if (i != j) {
        P_real[i, j] ~ normal(Pmu[2], 1 / sqrt(Pomega[2]));
      }
    }
  }

  // latent state means
  for (i in 2 : n) {
    mu[i] = A * (LV[i - 1] - trend_mus[ytimes_trend[i - 1, 1 : n_lv]]);
  }

  // dynamic process models

  // prior for s(week)_trend...
  b_raw_trend[1 : 10] ~ multi_normal_prec(zero_trend[1 : 10],
                                          S_trend1[1 : 10, 1 : 10]
                                          * lambda_trend[1]);

  // prior for s(week):trendtrend1_trend...
  b_raw_trend[11 : 20] ~ multi_normal_prec(zero_trend[11 : 20],
                                           S_trend2[1 : 10, 1 : 10]
                                           * lambda_trend[2]);

  // prior for s(week):trendtrend2_trend...
  b_raw_trend[21 : 30] ~ multi_normal_prec(zero_trend[21 : 30],
                                           S_trend3[1 : 10, 1 : 10]
                                           * lambda_trend[3]);

  // prior for s(week):trendtrend3_trend...
  b_raw_trend[31 : 40] ~ multi_normal_prec(zero_trend[31 : 40],
                                           S_trend4[1 : 10, 1 : 10]
                                           * lambda_trend[4]);

  // prior for s(week):trendtrend4_trend...
  b_raw_trend[41 : 50] ~ multi_normal_prec(zero_trend[41 : 50],
                                           S_trend5[1 : 10, 1 : 10]
                                           * lambda_trend[5]);

  // prior for s(week):trendtrend5_trend...
  b_raw_trend[51 : 60] ~ multi_normal_prec(zero_trend[51 : 60],
                                           S_trend6[1 : 10, 1 : 10]
                                           * lambda_trend[6]);
  lambda_trend ~ normal(5, 30);
  sigma_raw_trend ~ exponential(0.33);
  mu_raw_trend ~ normal(-4.1, 1);
  b_raw_trend[trend_rand_idxs] ~ std_normal();
  LV[1] ~ multi_normal(trend_mus[ytimes_trend[1, 1 : n_lv]], Gamma);
  for (i in 2 : n) {
    LV[i] ~ multi_normal_cholesky(trend_mus[ytimes_trend[i, 1 : n_lv]] + mu[i],
                                  L_Sigma);
  }

  // priors for precision parameters
  phi ~ gamma(0.01, 0.01);
  {
    // likelihood functions
    vector[n_nonmissing] flat_trends;
    vector[n_nonmissing] flat_phis;
    flat_trends = to_vector(trend)[obs_ind];
    flat_phis = rep_each(phi, n)[obs_ind];
    flat_ys ~ beta(inv_logit(append_col(flat_xs, flat_trends)
                             * append_row(b, 1.0))
                   .* flat_phis,
                   (1
                    - inv_logit(append_col(flat_xs, flat_trends)
                                * append_row(b, 1.0)))
                   .* flat_phis);
  }
}
generated quantities {
  vector[total_obs] eta;
  matrix[n, n_series] phi_vec;
  matrix[n, n_series] mus;
  vector[n_sp_trend] rho_trend;
  array[n, n_series] real<lower=0, upper=1> ypred;
  rho_trend = log(lambda_trend);

  // posterior predictions
  eta = X * b;
  for (s in 1 : n_series) {
    phi_vec[1 : n, s] = rep_vector(phi[s], n);
  }
  for (s in 1 : n_series) {
    mus[1 : n, s] = eta[ytimes[1 : n, s]] + trend[1 : n, s];
    ypred[1 : n, s] = beta_rng(inv_logit(mus[1 : n, s]) .* phi_vec[1 : n, s],
                               (1 - inv_logit(mus[1 : n, s]))
                               .* phi_vec[1 : n, s]);
  }
}
